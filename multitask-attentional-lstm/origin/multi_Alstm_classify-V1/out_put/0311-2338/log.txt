WARNING:tensorflow:From ./models/attn_bi_lstm.py:39: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
2020-03-11 23:39:02.209561: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-11 23:39:02.479916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:04:00.0
totalMemory: 10.73GiB freeMemory: 5.69GiB
2020-03-11 23:39:02.479994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-03-11 23:39:03.070971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-11 23:39:03.071026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-03-11 23:39:03.071037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-03-11 23:39:03.071315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5444 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
Process ID: 150300, Process Parent ID: 1
Config_File = ./Config/config.cfg
Extra_Args = []
self.save_dir ./Config/config.cfg
Loaded config file sucessfully!
data_dir = ./data_20000_node
max_len = 32
min_len_word = 1
concat_in_node = False
segment = pyltp
cws_model_path = /home/zengbin.gao/NLP/cws.model
classification_combine = True
use_cols = type_robot,msg_del_dup,type,type_combine
cls_type = ask_know,ask_today,ask_tomorrow,once,request,twice,identity,dealh,dealml
save_dir = ./out_put/out_put_03_11_01
tokenizer_path = ./out_put/out_put_03_11_01/this_tokenizer.pickle
config_path = ./out_put/out_put_03_11_01/this_config.cfg
model_path = ./out_put/out_put_03_11_01/this_config.cfg
save_model_name = MyModel
checkpoint_from_epoch = 0
checkpoint_num = 2
train_sample = ./out_put/out_put_03_11_01/train-sample
test_sample = ./out_put/out_put_03_11_01/test-sample
use_cuda = False
device = -1
vocab_size = 0
n_class = 0
embedding_size = 128
hidden_size = 128
dropout_keep_prob = 0.5
learning_rate = 0.0012
keep_prob = 0.5
num_layers = 2
is_train = True
train_epochs = 30
train_steps = 50
batch_size = 32
evaluate_every = 100
path_model_predict = ./out_put/out_put_03_11_01
name_model_predict = MyModel
seed_num = 666

Loading Data......
name ask_know
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 8679 / 952
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name ask_today
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 23086 / 880
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name ask_tomorrow
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 14232 / 531
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name once
Train[type_combine]: ['deny_money' 'invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 28353 / 5208
Number of classification: 4
type2id: {'deny_money': 0, 'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name request
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 3388 / 575
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name twice
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 24411 / 584
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name identity
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 22542 / 8622
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name dealh
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 1532 / 384
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
name dealml
Train[type_combine]: ['invalid' 'no' 'yes']
Test[type_combine]: ['invalid' 'no' 'yes']
Length Train / Test : 4868 / 1217
Number of classification: 3
type2id: {'invalid': 0, 'no': 2, 'yes': 1}.
id2type: {0: 'invalid', 2: 'no', 1: 'yes'}.
Using PyLTP to do chinese-word-segment......
Using PyLTP to do chinese-word-segment......
dict_id {0: 'invalid', 2: 'no', 1: 'yes'}
Successfully saved the tokenizer to ./out_put/out_put_03_11_01/this_tokenizer.pickle
n_class = 3
vocab_size = 131093
class 3
cls_type ['ask_know', 'ask_today', 'ask_tomorrow', 'once', 'request', 'twice', 'identity', 'dealh', 'dealml']
building graph
graph built successfully!

#### Current Train Epoch: 1 ####
Traceback (most recent call last):
  File "./models/attn_bi_lstm.py", line 159, in <module>
    for x_batch, y_batch, class_name, seq_l_batch, _ in fill_feed_dict(train_x, train_y, class_train, seq_l_train, (train_texts, train_real_type), config.batch_size):
  File "/home/fangshu.chang/multi_alstm_classify/multi_Alstm_classify-V1/utils/data_helper.py", line 254, in fill_feed_dict
    seq_l_predict_batch.append(seq_l_predict[batch_size * idx: batch_size * (idx + 1)])
NameError: name 'seq_l_predict_batch' is not defined
