[Data]
data_dir = ./data_20000_node
# max_len: 序列最大长度
max_len = 32
# min_len_word: 过滤掉Text里长度小于min_len_word的词
min_len_word = 1
# concat_in_node: 是否拼接in_node节点
concat_in_node = False

# segment: 分词工具[jieba, pyltp]
segment = pyltp
#词典大小
vocab_size=10000

vocab_path = ./gzb_vocab.txt

cws_model_path = /home/zengbin.gao/NLP/cws.model
# classification_combine: 是否进行类别合并 即使用type or type_combine
#classification_combine = True
# 读取哪些列
#use_cols = type_robot,msg_del_dup,type,type_combine
use_cols = type_robot,msg_del_dup,type_combine
#类别
cls_type = ask_know,ask_today,ask_tomorrow,once,request,twice,identity,dealh,dealml



[Save]
# 模型保存路径
save_dir = ./out_put/out_put_03_13
# tokenizer_path = %(save_dir)s/this_tokenizer.pickle
config_path = %(save_dir)s/this_config.cfg
model_path = %(save_dir)s/this_config.cfg
# 模型保存名字
save_model_name = MyModel
# 训练checkpoint_from_epoch轮后开始 测试&保存 模型&样例
checkpoint_from_epoch = 0
# 仅保存最近的checkpoint_num个模型
checkpoint_num = 2
# 保存样例的路径前缀
train_sample = %(save_dir)s/train-sample
#dev_sample = %(save_dir)s/dev-sample
test_sample = %(save_dir)s/test-sample



[Device]
use_cuda = False
device = -1

[Model]
#vocab_size = 0
n_class = 0
embedding_size = 128
hidden_size = 128
# filter_sizes = 3,5,7
# num_filters = 128
dropout_keep_prob = 0.5
learning_rate = 0.0012
# l2_reg_lambda = 0.008
keep_prob = 0.5
num_layers = 1


[Run]
#是否训练
is_train = False
# 训练轮次
train_epochs = 60
# 训练train_step步/个batch后打印信息
train_steps = 50
batch_size = 32
evaluate_every = 100

[Predict]
# 模型路径
path_model_Predict = ./out_put/out_put_03_13
name_model_Predict = MyModel


